{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification aggregator for bioschemas\n",
    "\n",
    "The DDE intentionally does not allow existing namespaces to be used by others. This is a feature that ensures that user-generated schemas or user-customized schemas are not confused for existing, registered schemas. Unfortunately, this means that users looking to update an existing bioschemas cannot use the bioschemas namespace when creating a schema within the DDE. The aggregator includes a function will replace the temporary namespace with the bioschemas namespace for the merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What this script does\n",
    "\n",
    "1. Loads the list of jsonschema specification files to ingest\n",
    "2. Replaces the temporary namespace in the merged json document\n",
    "3. Include a check for multiple same classes: \n",
    "  * A profile might reference another profile. In order for the profile to work, a dummy class of the referenced profile may need to be created. This dummy profile should be included in the merged file ONLY IF the actual class (which should have a validation section of its own) does not exist\n",
    "  * Use the existence of a validation to determine which class to keep in the event of the same class coming from different profiles (real or dummy)\n",
    "4. Includes a check for the subclass of and update it to match the list \n",
    "  * This is in anticipation of the use of the DDE to update an existing profile\n",
    "5. Includes a check for multiple same properties:\n",
    "  * A single property might be used across different bioschemas classes\n",
    "  * This means that the `\"schema:domainIncludes\"` property should be updated to reflect ALL of the classes that use it, rather than just the first class that uses it.\n",
    "  * eg- \"bioschemas:output\" might be a property in \"ComputationalTool\" and \"ComputationalWorkflow\". Since these profiles are developed separately, the one in \"ComputationalTool\" will include `\"schema:domainIncludes\": {\"@id\": \"bioschemas:ComputationalTool\"}` while the one from ComputationalWorkflow will include `\"schema:domainIncludes\": {\"@id\": \"bioschemas:ComputationalWorkflow\"}`. These will need to be merged into a single property with `\"schema:domainIncludes\": [{\"@id\": \"bioschemas:ComputationalTool\"},{\"@id\": \"bioschemas:ComputationalWorkflow\"}]`\n",
    "6. Include a check for the proper url for bioschemas in @context\n",
    "7. Automatically include `dct:conformsTo` to all classes definied by the schema\n",
    "8. Automatically include `schema:schemaVersion` to all classes defined by the schema\n",
    "\n",
    "Note - As of 2022.02.17 - the script will split out types and profiles which will be saved to different json files and ingested into the DDE under different namespaces.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "1. Include a check for properties which already have a list for the domainIncludes\n",
    "2. Ensure script works even with extra data in table\n",
    "3. Add schema validation check before allowing it to commit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from biothings_schema import Schema\n",
    "from src.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_updates(script_path,updateall=False):\n",
    "    checktime = datetime.now()\n",
    "    profile_file = os.path.join(script_path,'profile_list.txt')\n",
    "    profile_draft_file = os.path.join(script_path,'draft_profile_list.txt')\n",
    "    type_file = os.path.join(script_path,'type_list.txt')\n",
    "    type_draft_file = os.path.join(script_path,'draft_type_list.txt')\n",
    "    deprecated = os.path.join(script_path,'deprecated.txt')\n",
    "    filelist = [profile_file,profile_draft_file,type_file,type_draft_file,deprecated]\n",
    "    updatedlist = []\n",
    "    if updateall==True:\n",
    "        updatedlist = filelist\n",
    "    else:\n",
    "        for eachfile in filelist:\n",
    "            last_modified = datetime.fromtimestamp(os.path.getmtime(eachfile))\n",
    "            timediff = checktime-last_modified\n",
    "            if timediff < timedelta(hours=3):\n",
    "                updatedlist.append(eachfile)\n",
    "    if len(updatedlist)==0:\n",
    "        updatedlist = False\n",
    "    return updatedlist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_update(script_path,updateall=False):\n",
    "    if updateall == True:\n",
    "        updatedlist = check_for_updates(script_path,True)\n",
    "    else:\n",
    "        updatedlist = check_for_updates(script_path,False)\n",
    "    if updatedlist != False:\n",
    "        for eachfile in updatedlist:\n",
    "            speclist = read_csv(eachfile,delimiter='\\t',header=0)\n",
    "            bioschemas_json = remove_NaN_fields(merge_specs(speclist))\n",
    "            jsonstring = json.dumps(bioschemas_json)\n",
    "            cleanstring = remove_NaN_fields(jsonstring)\n",
    "            cleandict = json.loads(cleanstring)\n",
    "            prettystring = json.dumps(cleandict, indent=2)\n",
    "            #### Check specification list file name to determine where to save\n",
    "            if \"deprecated\" in eachfile:\n",
    "                ####treat as deprecated\n",
    "                bioschemasfile = os.path.join(script_path,'bioschemasdeprecated.json')\n",
    "            if \"type\" in eachfile:\n",
    "                if \"draft\" in eachfile:\n",
    "                    #### draft type treat as type \n",
    "                    bioschemasfile = os.path.join(script_path,'bioschemastypesdrafts.json')\n",
    "                else:\n",
    "                    ####treat as type\n",
    "                    bioschemasfile = os.path.join(script_path,'bioschemastypes.json')\n",
    "            if \"profile\" in eachfile:\n",
    "                if \"draft\" in eachfile:\n",
    "                    ####treat as draft profile\n",
    "                    bioschemasfile = os.path.join(script_path,'bioschemasdrafts.json')\n",
    "                else:\n",
    "                    bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "            sc = Schema(cleandict, base_schema=[\"schema.org\",\"bioschemastypes\",\"bioschemas\",\n",
    "                              \"bioschemasdrafts\",\"bioschemastypesdrafts\",\n",
    "                              \"bioschemasdeprecated\"])\n",
    "            with open(bioschemasfile,'w') as outfile:\n",
    "                outfile.write(prettystring)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_url(url):\n",
    "    if 'raw' not in url:\n",
    "        rawrawurl = url.replace('github.com','raw.githubusercontent.com')\n",
    "        if 'master' in rawrawurl:\n",
    "            rawurl = rawrawurl.replace('/blob/master/','/master/')\n",
    "        elif 'main' in rawrawurl:\n",
    "            rawurl = rawrawurl.replace('/blob/main/','/main/')\n",
    "    else:\n",
    "        rawurl = url\n",
    "    return rawurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_namespace(spec_list,eachurl,rawtext):\n",
    "    tmpinfo = spec_list.loc[spec_list['url']==eachurl]\n",
    "    tmpnamespace = tmpinfo.iloc[0]['namespace']\n",
    "    if 'DEPRECATED' in tmpinfo.iloc[0]['version']:\n",
    "        if tmpnamespace!='bioschemasdeprecated':\n",
    "            tmptext = '\"@id\": \"'+tmpnamespace+':'\n",
    "            cleantext = rawtext.replace(tmptext,'\"@id\": \"bioschemasdeprecated:')\n",
    "        else:\n",
    "            cleantext = rawtext \n",
    "    elif ((tmpinfo.iloc[0]['type']=='Profile') and ('RELEASE' in tmpinfo.iloc[0]['version'])):\n",
    "        if tmpnamespace!='bioschemas':\n",
    "            tmptext = '\"@id\": \"'+tmpnamespace+':'\n",
    "            cleantext = rawtext.replace(tmptext,'\"@id\": \"bioschemas:')\n",
    "        else:\n",
    "            cleantext = rawtext\n",
    "    elif ((tmpinfo.iloc[0]['type']=='Profile') and ('DRAFT' in tmpinfo.iloc[0]['version'])):\n",
    "        if tmpnamespace!='bioschemasdrafts':\n",
    "            tmptext = '\"@id\": \"'+tmpnamespace+':'\n",
    "            cleantext = rawtext.replace(tmptext,'\"@id\": \"bioschemasdrafts:')\n",
    "        else:\n",
    "            cleantext = rawtext  \n",
    "    elif ((tmpinfo.iloc[0]['type']=='Type') and ('RELEASE' in tmpinfo.iloc[0]['version'])):\n",
    "        if tmpnamespace!='bioschemastypes':\n",
    "            tmptext = '\"@id\": \"'+tmpnamespace+':'\n",
    "            cleantext = rawtext.replace(tmptext,'\"@id\": \"bioschemastypes:')\n",
    "        else:\n",
    "            cleantext = rawtext\n",
    "    elif ((tmpinfo.iloc[0]['type']=='Type') and ('DRAFT' in tmpinfo.iloc[0]['version'])):\n",
    "        if tmpnamespace!='bioschemastypesdrafts':\n",
    "            tmptext = '\"@id\": \"'+tmpnamespace+':'\n",
    "            cleantext = rawtext.replace(tmptext,'\"@id\": \"bioschemastypesdrafts:')\n",
    "        else:\n",
    "            cleantext = rawtext\n",
    "    return(cleantext, tmpnamespace)\n",
    "\n",
    "\n",
    "def generate_base_context():\n",
    "    allcontext = {\n",
    "        \"schema\": \"http://schema.org/\",\n",
    "        \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "        \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n",
    "        \"owl\":\"http://www.w3.org/2002/07/owl/\",\n",
    "        \"bioschemas\":\"https://discovery.biothings.io/view/bioschemas/\",\n",
    "        \"bioschemasdrafts\":\"https://discovery.biothings.io/view/bioschemasdrafts/\",\n",
    "        \"bioschemastypes\":\"https://discovery.biothings.io/view/bioschemastypes/\",\n",
    "        \"bioschemastypesdrafts\":\"https://discovery.biothings.io/view/bioschemastypesdrafts/\",\n",
    "        \"bioschemasdeprecated\":\"https://discovery.biothings.io/view/bioschemasdeprecated/\",\n",
    "        \"dct\":\"http://purl.org/dc/terms/\"\n",
    "    }\n",
    "    return allcontext\n",
    "\n",
    "def check_context_url(allcontext,spec_json,tmpnamespace):\n",
    "    now = datetime.now()\n",
    "    contextInfo = spec_json['@context']\n",
    "    for key in list(contextInfo.keys()):\n",
    "        if key != tmpnamespace: \n",
    "            if key not in list(allcontext.keys()):\n",
    "                allcontext[key] = contextInfo[key]\n",
    "    allcontext[\"@dateModified\"] = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    return allcontext\n",
    "\n",
    "def update_subclass(spec_list,eachurl,cleantext):\n",
    "    spec_json = json.loads(cleantext)\n",
    "    tmpinfo = spec_list.loc[spec_list['url']==eachurl]\n",
    "    tmpsubclass = tmpinfo.iloc[0]['subClassOf']\n",
    "    classname = tmpinfo.iloc[0]['name']\n",
    "    truesubclass = {\"@id\": tmpsubclass}\n",
    "    for x in spec_json['@graph']:\n",
    "        if x['@id']==\"bioschemas:\"+classname:\n",
    "            x['rdfs:subClassOf']=truesubclass\n",
    "        if x['@id']==\"bioschemasdrafts:\"+classname:\n",
    "            x['rdfs:subClassOf']=truesubclass\n",
    "        if x['@id']==\"bioschemastypes:\"+classname:\n",
    "            x['rdfs:subClassOf']=truesubclass\n",
    "        if x['@id']==\"bioschemastypesdrafts:\"+classname:\n",
    "            x['rdfs:subClassOf']=truesubclass\n",
    "        if x['@id']==\"bioschemasdeprecated:\"+classname:\n",
    "            x['rdfs:subClassOf']=truesubclass\n",
    "    return spec_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletenamespace(x):\n",
    "    oldname = x['@id']\n",
    "    if \"bioschemastypesdrafts\" in oldname:\n",
    "        cleanname = oldname.replace(\"bioschemastypesdrafts:\",\"\")        \n",
    "    elif \"bioschemastypes\" in oldname:\n",
    "        cleanname = oldname.replace(\"bioschemastypes:\",\"\")\n",
    "    elif \"bioschemasdrafts\" in oldname:\n",
    "        cleanname = oldname.replace(\"bioschemasdrafts:\",\"\")\n",
    "    elif \"bioschemasdeprecated\" in oldname:\n",
    "        cleanname = oldname.replace(\"bioschemasdeprecated:\",\"\")\n",
    "    elif \"bioschemas\" in oldname:\n",
    "        cleanname = oldname.replace(\"bioschemas:\",\"\")\n",
    "    return cleanname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conformsTo(spec_list,x):\n",
    "    cleanname = deletenamespace(x)\n",
    "    spec_info = spec_list.loc[spec_list['name'] == cleanname]\n",
    "    spec_url = spec_info.iloc[0]['url']\n",
    "    conformsTodict = {\n",
    "            \"description\": \"This is used to state the Bioschemas profile that the markup relates to. The identifier can be the url for the version of this bioschemas class on github: \"+spec_url,\n",
    "            \"$ref\": \"#/definitions/conformsDefinition\"\n",
    "          }\n",
    "    conformdef={\n",
    "                \"@type\": \"CreativeWork\",\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"identifier\":{\n",
    "                    \"description\": \"The url of the version bioschemas profile that was used. For jsonschema, set @id to the identifier\",\n",
    "                    \"oneOf\": [\n",
    "                      {\n",
    "                        \"enum\": [spec_url] \n",
    "                      },\n",
    "                      {\n",
    "                        \"type\": \"string\",\n",
    "                        \"format\": \"uri\"\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                },\n",
    "                \"required\": [\n",
    "                  \"identifier\"\n",
    "                ]              \n",
    "        }\n",
    "    x['$validation']['properties']['conformsTo'] = conformsTodict\n",
    "    requirementlist = x['$validation']['required']\n",
    "    requirementlist.append('conformsTo')\n",
    "    x['$validation']['required'] = requirementlist\n",
    "    try:\n",
    "        definitiondict = x['$validation']['definitions']\n",
    "    except:\n",
    "        definitiondict = {}\n",
    "    definitiondict[\"conformsDefinition\"]=conformdef\n",
    "    x['$validation']['definitions']=definitiondict\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_conformsTo(x):\n",
    "    if 'conformsTo' in list(x['$validation']['properties'].keys()):\n",
    "        del x['$validation']['properties']['conformsTo']\n",
    "        requirementlist = [i for i in x['$validation']['required'] if i!='conformsTo']\n",
    "        x['$validation']['required'] = requirementlist\n",
    "    if 'definitions' in list(x['$validation']):\n",
    "        if 'conformsTo' in list(x['$validation']['definitions'].keys()):\n",
    "            del x['$validation']['definitions']['conformsTo']\n",
    "        if 'conformsDefinition' in list(x['$validation']['definitions'].keys()):\n",
    "             del x['$validation']['definitions']['conformsDefinition']\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_schemaVersion(spec_list,x):\n",
    "    cleanname = deletenamespace(x)\n",
    "    spec_info = spec_list.loc[spec_list['name'] == cleanname]\n",
    "    spec_url = spec_info.iloc[0]['url']\n",
    "    baseurl = \"https://bioschemas.org\"\n",
    "    versionurl = baseurl+'/'+spec_info.iloc[0]['type'].lower()+'s/'+spec_info.iloc[0]['name']+'/'+spec_info.iloc[0]['version']\n",
    "    try:\n",
    "        existingversions = x[\"schema:schemaVersion\"]\n",
    "        if isinstance(schemaversions, list) == False:\n",
    "            schemaversions = existingversions.strip(\"[\").strip(\"]\").split(\",\")\n",
    "        else:\n",
    "            schemaversions = existingversions\n",
    "    except:\n",
    "        schemaversions = []\n",
    "    schemaversions.append(versionurl)\n",
    "    schemaversions.append(spec_url)\n",
    "    ## Ensure uniqueness of elements\n",
    "    x[\"schema:schemaVersion\"] = list(set(schemaversions))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_specification_type(spec_list,x):\n",
    "    cleanname = deletenamespace(x)\n",
    "    spec_info = spec_list.loc[spec_list['name'] == cleanname]\n",
    "    if spec_list.iloc[0]['type']=='Type':\n",
    "        baseurl = 'https://bioschemas.org/types#nav-'\n",
    "    elif spec_list.iloc[0]['type']=='Profile':\n",
    "        baseurl = 'https://bioschemas.org/profiles#nav-'\n",
    "    if 'deprecated' in spec_info.iloc[0]['version'].lower():\n",
    "        typeurl = baseurl+'deprecated'\n",
    "    elif 'release' in spec_info.iloc[0]['version'].lower():\n",
    "        typeurl = baseurl+'release'\n",
    "    elif 'draft' in spec_info.iloc[0]['version'].lower():\n",
    "        typeurl = baseurl+'draft'\n",
    "    x['additional_type'] = typeurl\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_specs(spec_list):\n",
    "    bioschemas_json = {}\n",
    "    graphlist = []\n",
    "    classlist = []\n",
    "    propertylist = []\n",
    "    allcontext = generate_base_context()\n",
    "    for eachurl in spec_list['url']:\n",
    "        rawurl = get_raw_url(eachurl)\n",
    "        r = requests.get(rawurl)\n",
    "        if r.status_code == 200:\n",
    "            cleantext,tmpnamespace = rename_namespace(spec_list,eachurl,r.text)\n",
    "            spec_json = json.loads(cleantext)\n",
    "            allcontext = check_context_url(allcontext,spec_json,tmpnamespace)\n",
    "            for x in spec_json['@graph']:\n",
    "                graphlist.append(x)\n",
    "                if x[\"@type\"]==\"rdfs:Class\":\n",
    "                    classlist.append(x[\"@id\"])\n",
    "                if x[\"@type\"]==\"rdf:Property\":\n",
    "                    propertylist.append(x[\"@id\"])\n",
    "    cleanclassgraph = clean_duplicate_classes(spec_list,graphlist,classlist)\n",
    "    cleanpropsgraph = clean_duplicate_properties(graphlist, propertylist)\n",
    "    cleangraph = []\n",
    "    for z in cleanclassgraph:\n",
    "        cleangraph.append(z)\n",
    "    for a in cleanpropsgraph:\n",
    "        cleangraph.append(a)\n",
    "    conformsTo = define_conformsTo(classlist)\n",
    "    cleangraph.append(conformsTo)\n",
    "    bioschemas_json['@context'] = check_context_url(allcontext,spec_json,tmpnamespace)\n",
    "    bioschemas_json['@graph']=cleangraph\n",
    "    return bioschemas_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duplicate_classes(spec_list,graphlist,classlist):\n",
    "    duplicates = [i for i in set(classlist) if classlist.count(i) > 1]\n",
    "    nondupes = [x for x in classlist if x not in duplicates]\n",
    "    cleanclassgraph = []\n",
    "    if len(duplicates)>0:  ## There are duplicate classes to clean up\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                x = add_specification_type(spec_list,x)\n",
    "                x = add_schemaVersion(spec_list,x)\n",
    "                if \"$validation\" in x.keys():\n",
    "                    x = remove_conformsTo(x)\n",
    "                    x = add_conformsTo(spec_list,x)\n",
    "                cleanclassgraph.append(x)\n",
    "            for eachclass in duplicates:\n",
    "                if x[\"@id\"]==eachclass:\n",
    "                    x = add_specification_type(spec_list,x)\n",
    "                    x = add_schemaVersion(spec_list,x)\n",
    "                    if \"$validation\" in x.keys():\n",
    "                        x = remove_conformsTo(x)\n",
    "                        x = add_conformsTo(spec_list,x)\n",
    "                    cleanclassgraph.append(x)\n",
    "    else:  ## There are no duplicate classes to clean up\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                x = add_specification_type(spec_list,x)\n",
    "                x = add_schemaVersion(spec_list,x)\n",
    "                if \"$validation\" in x.keys():\n",
    "                    x = remove_conformsTo(x)\n",
    "                    x = add_conformsTo(spec_list,x)\n",
    "                cleanclassgraph.append(x)        \n",
    "    return cleanclassgraph \n",
    "\n",
    "def clean_duplicate_properties(graphlist, propertylist):\n",
    "    if 'conformsTo' in propertylist:\n",
    "        propertylist.remove('conformsTo')\n",
    "    if 'dct:conformsTo' in propertylist:\n",
    "        propertylist.remove('dct:conformsTo')\n",
    "    duplicates = [i for i in set(propertylist) if propertylist.count(i) > 1]\n",
    "    nondupes = [x for x in propertylist if x not in duplicates]\n",
    "    cleanpropsgraph = []\n",
    "    dupepropsgraph = []\n",
    "    if len(duplicates)>0:  ## There are duplicate properties to clean up\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                x = remove_NaN_fields(x)\n",
    "                cleanpropsgraph.append(x)\n",
    "            elif x[\"@id\"] in duplicates:\n",
    "                x = remove_NaN_fields(x)\n",
    "                dupepropsgraph.append(x)\n",
    "        #dupepropsgraph[0][\"dummyProp\"]={\"@id\":\"dummyValue\"} #### creates dummy property for testing only\n",
    "        dupepropsdf = pd.DataFrame(dupepropsgraph)\n",
    "        for eachprop in duplicates:\n",
    "            tmpdf = dupepropsdf.loc[dupepropsdf['@id']==eachprop].copy()\n",
    "            domainlist = []\n",
    "            domainlist = [y for y in tmpdf[\"schema:domainIncludes\"] if y not in domainlist]\n",
    "            #### Get the row with the least number of NaNs (ie- the row with the most properties) to serve as the base property\n",
    "            tmpdf[\"nullcount\"]=tmpdf.isnull().sum(axis=1)\n",
    "            tmpdf.sort_values(\"nullcount\",ascending=True,inplace=True)\n",
    "            tmpdict = tmpdf.iloc[0].to_dict()\n",
    "            del tmpdict[\"nullcount\"]\n",
    "            tmpdict[\"schema:domainIncludes\"]=domainlist #### Set the domainIncludes list\n",
    "            cleanpropsgraph.append(tmpdict)       \n",
    "    else:\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                x = remove_NaN_fields(x)\n",
    "                cleanpropsgraph.append(x)\n",
    "    return cleanpropsgraph   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_conformsTo(classlist):\n",
    "    uniqueclasses =  list(set(classlist))\n",
    "    classidlist = [{\"@id\":x} for x in classlist]\n",
    "    conformsTo = {\n",
    "      \"@id\": \"dct:conformsTo\",\n",
    "      \"@type\": \"rdf:Property\",\n",
    "      \"rdfs:comment\": \"Used to state the Bioschemas profile that the markup relates to. The versioned URL of the profile must be used. Note that we use a CURIE in the table here but the full URL for Dublin Core terms must be used in the markup (http://purl.org/dc/terms/conformsTo), see example.\",\n",
    "      \"rdfs:label\": \"conformsTo\",\n",
    "      \"schema:domainIncludes\": classidlist,\n",
    "      \"schema:rangeIncludes\": [\n",
    "        {\"@id\": \"schema:CreativeWork\"},{\"@id\": \"schema:Text\"},{\"@id\": \"schema:Thing\"}\n",
    "      ]\n",
    "    }\n",
    "    return conformsTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_NaN_fields(propdef):\n",
    "    cleandict = {}\n",
    "    if isinstance(propdef,dict):\n",
    "        for k, v in propdef.items():\n",
    "            if k != \"schema:sameAs\":\n",
    "                cleandict[k]=v\n",
    "            elif k == \"schema:sameAs\": \n",
    "                if isinstance(v,type(None))==False:\n",
    "                    cleandict[k]=v\n",
    "    if isinstance(propdef,str):\n",
    "        cleandict = propdef.replace(', \"schema:sameAs\": NaN','')\n",
    "        cleandict = cleandict.replace('\"schema:sameAs\": NaN, ','')\n",
    "    return cleandict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ['profile_list.txt', 'draft_profile_list.txt', 'type_list.txt', 'draft_type_list.txt', 'deprecated.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\biothings_schema\\schema.py:280: UserWarning: Found multiple namespace prefixes defined in the schema: f['bioschemas', 'dwc', 'dct']\n",
      "  warnings.warn(f\"Found multiple namespace prefixes defined in the schema: f{namespace_set}\")\n",
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\biothings_schema\\schema.py:280: UserWarning: Found multiple namespace prefixes defined in the schema: f['bioschemasdrafts', 'ppeo', 'dct', 'rdf', 'dwc']\n",
      "  warnings.warn(f\"Found multiple namespace prefixes defined in the schema: f{namespace_set}\")\n",
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\biothings_schema\\schema.py:280: UserWarning: Found multiple namespace prefixes defined in the schema: f['bioschemastypes', 'dct']\n",
      "  warnings.warn(f\"Found multiple namespace prefixes defined in the schema: f{namespace_set}\")\n",
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\biothings_schema\\schema.py:280: UserWarning: Found multiple namespace prefixes defined in the schema: f['bioschemastypesdrafts', 'dct']\n",
      "  warnings.warn(f\"Found multiple namespace prefixes defined in the schema: f{namespace_set}\")\n",
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\biothings_schema\\schema.py:280: UserWarning: Found multiple namespace prefixes defined in the schema: f['bioschemasdrafts', 'rdf', 'dct']\n",
      "  warnings.warn(f\"Found multiple namespace prefixes defined in the schema: f{namespace_set}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from biothings_schema import Schema\n",
    "from src.common import *\n",
    "\n",
    "#### Main\n",
    "script_path = '' #pathlib.Path(__file__).parent.absolute()\n",
    "run_update(script_path,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For additional Testing if \"run_update\" fails\n",
    "\n",
    "spec_list = speclist\n",
    "duplicates = [i for i in set(classlist) if classlist.count(i) > 1]\n",
    "nondupes = [x for x in classlist if x not in duplicates]\n",
    "cleanclassgraph = []\n",
    "if len(duplicates)>0:  ## There are duplicate classes to clean up\n",
    "    for x in graphlist:\n",
    "        if x[\"@id\"] in nondupes:\n",
    "            cleanname = deletenamespace(x)\n",
    "            spec_info = spec_list.loc[spec_list['name'] == cleanname]\n",
    "            if spec_list.iloc[0]['type']=='Type':\n",
    "                baseurl = 'https://bioschemas.org/types#nav-'\n",
    "            elif spec_list.iloc[0]['type']=='Profile':\n",
    "                baseurl = 'https://bioschemas.org/profiles#nav-'\n",
    "            if 'deprecated' in spec_info.iloc[0]['version'].lower():\n",
    "                typeurl = baseurl+'deprecated'\n",
    "            elif 'release' in spec_info.iloc[0]['version'].lower():\n",
    "                typeurl = baseurl+'release'\n",
    "            elif 'draft' in spec_info.iloc[0]['version'].lower():\n",
    "                typeurl = baseurl+'draft'\n",
    "            x['additional_type'] = typeurl            \n",
    "            #x = add_schemaVersion(spec_type,x)\n",
    "            if \"$validation\" in x.keys():\n",
    "                x = add_conformsTo(spec_type,x)\n",
    "            cleanclassgraph.append(x)\n",
    "        for eachclass in duplicates:\n",
    "            if x[\"@id\"]==eachclass:\n",
    "                cleanname = deletenamespace(x)\n",
    "                spec_info = spec_list.loc[spec_list['name'] == cleanname]\n",
    "                if spec_list.iloc[0]['type']=='Type':\n",
    "                    baseurl = 'https://bioschemas.org/types#nav-'\n",
    "                elif spec_list.iloc[0]['type']=='Profile':\n",
    "                    baseurl = 'https://bioschemas.org/profiles#nav-'\n",
    "                if 'deprecated' in spec_info.iloc[0]['version'].lower():\n",
    "                    typeurl = baseurl+'deprecated'\n",
    "                elif 'release' in spec_info.iloc[0]['version'].lower():\n",
    "                    typeurl = baseurl+'release'\n",
    "                elif 'draft' in spec_info.iloc[0]['version'].lower():\n",
    "                    typeurl = baseurl+'draft'\n",
    "                x['additional_type'] = typeurl   \n",
    "                #x = add_schemaVersion(spec_type,x)\n",
    "                if \"$validation\" in x.keys():\n",
    "                    x = add_conformsTo(spec_list,x)\n",
    "                cleanclassgraph.append(x)\n",
    "\n",
    "else:  ## There are not duplicate classes to clean up\n",
    "    for x in graphlist:\n",
    "        if x[\"@id\"] in nondupes:\n",
    "            cleanname = deletenamespace(x)\n",
    "            print(cleanname)\n",
    "            spec_info = spec_list.loc[spec_list['name'] == cleanname]\n",
    "            print(spec_info)\n",
    "            if spec_list.iloc[0]['type']=='Type':\n",
    "                baseurl = 'https://bioschemas.org/types#nav-'\n",
    "            elif spec_list.iloc[0]['type']=='Profile':\n",
    "                baseurl = 'https://bioschemas.org/profiles#nav-'\n",
    "            if 'deprecated' in spec_info.iloc[0]['version'].lower():\n",
    "                typeurl = baseurl+'deprecated'\n",
    "            elif 'release' in spec_info.iloc[0]['version'].lower():\n",
    "                typeurl = baseurl+'release'\n",
    "            elif 'draft' in spec_info.iloc[0]['version'].lower():\n",
    "                typeurl = baseurl+'draft'\n",
    "            x['additional_type'] = typeurl   \n",
    "            #x = add_schemaVersion(spec_type,x)     \n",
    "            if \"$validation\" in x.keys():\n",
    "                x = add_conformsTo(spec_list,x)\n",
    "            cleanclassgraph.append(x) \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For additional Testing if \"run_update\" fails\n",
    "\n",
    "updateall=False\n",
    "if updateall == True:\n",
    "    updatedlist = check_for_updates(script_path,True)\n",
    "else:\n",
    "    updatedlist = check_for_updates(script_path,False)\n",
    "    print(updatedlist)\n",
    "if updatedlist == False:\n",
    "    print(\"no updates pushed\")\n",
    "else:\n",
    "    for eachfile in updatedlist:\n",
    "        print(\"\")\n",
    "        print(eachfile)\n",
    "        speclist = read_csv(eachfile,delimiter='\\t',header=0)\n",
    "        print(speclist)\n",
    "        tmpinfo = merge_specs(speclist)\n",
    "        bioschemas_json = remove_NaN_fields(tmpinfo)\n",
    "        jsonstring = json.dumps(bioschemas_json)\n",
    "        cleanstring = remove_NaN_fields(jsonstring)\n",
    "        cleandict = json.loads(cleanstring)\n",
    "        prettystring = json.dumps(cleandict, indent=2)\n",
    "        #### Check specification list file name to determine where to save\n",
    "        if \"deprecated\" in eachfile:\n",
    "            print(\"deprecated: \", eachfile)\n",
    "            ####treat as deprecated\n",
    "            bioschemasfile = os.path.join(script_path,'bioschemasdeprecated.json')\n",
    "        elif ((\"type\" in eachfile) and (\"draft\" not in eachfile)):\n",
    "            print(\"type, release: \", eachfile)\n",
    "            ####treat as type\n",
    "            bioschemasfile = os.path.join(script_path,'bioschemastypes.json')\n",
    "        elif ((\"type\" in eachfile) and (\"draft\" in eachfile)):\n",
    "            print(\"type, draft: \", eachfile)\n",
    "            #### draft type treat as type \n",
    "            bioschemasfile = os.path.join(script_path,'bioschemastypesdrafts.json')\n",
    "        elif ((\"profile\" in eachfile) and (\"draft\" not in eachfile)):\n",
    "            print(\"profile, release: \", eachfile)\n",
    "            bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "        elif ((\"profile\" in eachfile) and (\"draft\" in eachfile)):\n",
    "            ####treat as draft profile\n",
    "            print(\"profile, draft: \", eachfile)\n",
    "            bioschemasfile = os.path.join(script_path,'bioschemasdrafts.json')\n",
    "        with open(bioschemasfile,'w') as outfile:\n",
    "            outfile.write(prettystring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a schema's compatibility with the DDE\n",
    "\n",
    "To do this, you will need to install the biothings schema tools: pip install git+https://github.com/biothings/biothings_schema.py#egg=biothings_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gtsueng\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\biothings_schema\\schema.py:280: UserWarning: Found multiple namespace prefixes defined in the schema: f['dct', 'dwc', 'bioschemas']\n",
      "  warnings.warn(f\"Found multiple namespace prefixes defined in the schema: f{namespace_set}\")\n"
     ]
    }
   ],
   "source": [
    "from biothings_schema import Schema\n",
    "\n",
    "script_path = ''\n",
    "#url = \"https://raw.githubusercontent.com/gtsueng/DDE_bioschemas/main/draft_validations/ProteinStructure_v0.5-DRAFT-2018_08_15.json\"\n",
    "url = \"https://raw.githubusercontent.com/BioSchemas/bioschemas-dde/main/bioschemas.json\"\n",
    "#bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "#with open(bioschemasfile,'r') as infile:\n",
    "#    url = json.load(infile)\n",
    "\n",
    "sc = Schema(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biothings_schema import Schema\n",
    "\n",
    "script_path = ''\n",
    "#url = \"https://raw.githubusercontent.com/gtsueng/DDE_bioschemas/main/draft_validations/ProteinStructure_v0.5-DRAFT-2018_08_15.json\"\n",
    "bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "with open(bioschemasfile,'r') as infile:\n",
    "    url = json.load(infile)\n",
    "\n",
    "sc = Schema(url, base_schema=[\"schema.org\",\"bioschemastypes\",\"bioschemas\",\n",
    "                              \"bioschemasdrafts\",\"bioschemastypesdrafts\",\n",
    "                              \"bioschemasdeprecated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated functions\n",
    "(Do not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note, while this version of the update script looks cleaner, it fails to perform as expected\n",
    "\n",
    "def run_update(script_path,updateall=False):\n",
    "    if updateall == True:\n",
    "        updatedlist = check_for_updates(script_path,True)\n",
    "    else:\n",
    "        updatedlist = check_for_updates(script_path,False)\n",
    "    if updatedlist != False:\n",
    "        for eachfile in updatedlist:\n",
    "            speclist = read_csv(eachfile,delimiter='\\t',header=0)\n",
    "            bioschemas_json = remove_NaN_fields(merge_specs(speclist))\n",
    "            jsonstring = json.dumps(bioschemas_json)\n",
    "            cleanstring = remove_NaN_fields(jsonstring)\n",
    "            cleandict = json.loads(cleanstring)\n",
    "            prettystring = json.dumps(cleandict, indent=2)\n",
    "            #### Check specification list file name to determine where to save\n",
    "            if \"deprecated\" in eachfile:\n",
    "                ####treat as deprecated\n",
    "                bioschemasfile = os.path.join(script_path,'bioschemasdeprecated.json')\n",
    "            elif ((\"type\" in eachfile) and (\"draft\" not in eachfile)):\n",
    "                ####treat as type\n",
    "                bioschemasfile = os.path.join(script_path,'bioschemastypes.json')\n",
    "            elif ((\"type\" in eachfile) and (\"draft\" in eachfile)):\n",
    "                #### draft type treat as type \n",
    "                bioschemasfile = os.path.join(script_path,'bioschemastypesdrafts.json')\n",
    "            elif ((\"profile\" in eachfile) and (\"draft\" not in eachfile)):\n",
    "                bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "            elif ((\"profile\" in eachfile) and (\"draft\" in eachfile)):\n",
    "                ####treat as draft profile\n",
    "                bioschemasfile = os.path.join(script_path,'bioschemasdrafts.json')\n",
    "            with open(bioschemasfile,'w') as outfile:\n",
    "                outfile.write(prettystring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### No longer in use\n",
    "\n",
    "def sort_speclist(spec_list):\n",
    "    spec_type = spec_list.loc[((spec_list['type']=='Type') and (spec_list['version'].str.contains('RELEASE')))].copy()\n",
    "    spec_profs = spec_list.loc[((spec_list['type']=='Profile') and (spec_list['version'].str.contains('RELEASE')))].copy()\n",
    "    draft_type = spec_list.loc[((spec_list['type']=='Type') and (spec_list['version'].str.contains('DRAFT')))].copy()\n",
    "    draft_profs = spec_list.loc[((spec_list['type']=='Profile') and (spec_list['version'].str.contains('DRAFT')))].copy()\n",
    "    return(spec_type,spec_profs,draft_type,draft_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Old method, do not use\n",
    "\n",
    "def update_specs(script_path):\n",
    "    spec_list = read_csv('specifications_list.txt',delimiter='\\t',header=0)\n",
    "    spec_type,spec_profs = sort_speclist(spec_list)\n",
    "    bioschemas_json = remove_NaN_fields(merge_specs(spec_profs))\n",
    "    bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "    jsonstring = json.dumps(bioschemas_json)\n",
    "    cleanstring = remove_NaN_fields(jsonstring)\n",
    "    with open(bioschemasfile,'w') as outfile:\n",
    "        outfile.write(cleanstring)\n",
    "    bioschemastype_json = remove_NaN_fields(merge_specs(spec_type))\n",
    "    bioschemastypefile = os.path.join(script_path,'bioschemastypes.json')\n",
    "    typejsonstring = json.dumps(bioschemastype_json)\n",
    "    typecleanstring = remove_NaN_fields(typejsonstring)\n",
    "    with open(bioschemastypefile,'w') as typeoutfile:\n",
    "        typeoutfile.write(typecleanstring)\n",
    "        \n",
    "## main\n",
    "script_path = \"\"\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "update_specs(script_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
