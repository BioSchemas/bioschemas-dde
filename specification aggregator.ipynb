{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification aggregator for bioschemas\n",
    "\n",
    "The DDE intentionally does not allow existing namespaces to be used by others. This is a feature that ensures that user-generated schemas or user-customized schemas are not confused for existing, registered schemas. Unfortunately, this means that users looking to update an existing bioschemas cannot use the bioschemas namespace when creating a schema within the DDE. The aggregator includes a function will replace the temporary namespace with the bioschemas namespace for the merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What this script does\n",
    "\n",
    "1. Loads the list of jsonschema specification files to ingest\n",
    "2. Replaces the temporary namespace in the merged json document\n",
    "3. Include a check for multiple same classes: \n",
    "  * A profile might reference another profile. In order for the profile to work, a dummy class of the referenced profile may need to be created. This dummy profile should be included in the merged file ONLY IF the actual class (which should have a validation section of its own) does not exist\n",
    "  * Use the existence of a validation to determine which class to keep in the event of the same class coming from different profiles (real or dummy)\n",
    "4. Includes a check for the subclass of and update it to match the list \n",
    "  * This is in anticipation of the use of the DDE to update an existing profile\n",
    "5. Includes a check for multiple same properties:\n",
    "  * A single property might be used across different bioschemas classes\n",
    "  * This means that the `\"schema:domainIncludes\"` property should be updated to reflect ALL of the classes that use it, rather than just the first class that uses it.\n",
    "  * eg- \"bioschemas:output\" might be a property in \"ComputationalTool\" and \"ComputationalWorkflow\". Since these profiles are developed separately, the one in \"ComputationalTool\" will include `\"schema:domainIncludes\": {\"@id\": \"bioschemas:ComputationalTool\"}` while the one from ComputationalWorkflow will include `\"schema:domainIncludes\": {\"@id\": \"bioschemas:ComputationalWorkflow\"}`. These will need to be merged into a single property with `\"schema:domainIncludes\": [{\"@id\": \"bioschemas:ComputationalTool\"},{\"@id\": \"bioschemas:ComputationalWorkflow\"}]`\n",
    "6. Include a check for the proper url for bioschemas in @context\n",
    "7. Automatically include `dct:conformsTo` to all classes definied by the schema\n",
    "8. Automatically include `schema:schemaVersion` to all classes defined by the schema\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "1. Include a check for properties which already have a list for the domainIncludes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_url(url):\n",
    "    if 'raw' not in url:\n",
    "        rawrawurl = url.replace('github.com','raw.githubusercontent.com')\n",
    "        if 'master' in rawrawurl:\n",
    "            rawurl = rawrawurl.replace('/blob/master/','/master/')\n",
    "        elif 'main' in rawrawurl:\n",
    "            rawurl = rawrawurl.replace('/blob/main/','/main/')\n",
    "    else:\n",
    "        rawurl = url\n",
    "    return(rawurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_namespace(spec_list,eachurl,rawtext):\n",
    "    tmpinfo = spec_list.loc[spec_list['url']==eachurl]\n",
    "    tmpnamespace = tmpinfo.iloc[0]['namespace']\n",
    "    if tmpnamespace!='bioschemas':\n",
    "        tmptext = '\"@id\": \"'+tmpnamespace+':'\n",
    "        cleantext = rawtext.replace(tmptext,'\"@id\": \"bioschemas:')\n",
    "    else:\n",
    "        cleantext = rawtext\n",
    "    return(cleantext)\n",
    "\n",
    "def check_context_url(spec_json):\n",
    "    contextInfo = spec_json['@context']\n",
    "    bioschemasUrl = \"https://discovery.biothings.io/view/bioschemas/\"\n",
    "    contextInfo[\"bioschemas\"]=bioschemasUrl\n",
    "    contextInfo[\"dct\"] = \"http://purl.org/dc/terms/\"\n",
    "    return(contextInfo)\n",
    "\n",
    "def update_subclass(spec_list,eachurl,cleantext):\n",
    "    spec_json = json.loads(cleantext)\n",
    "    tmpinfo = spec_list.loc[spec_list['url']==eachurl]\n",
    "    tmpsubclass = tmpinfo.iloc[0]['subclassOf']\n",
    "    classname = tmpinfo.iloc[0]['name']\n",
    "    truesubclass = {\"@id\": tmpsubclass}\n",
    "    for x in spec_json['@graph']:\n",
    "        if x['@id']==\"bioschemas:\"+classname:\n",
    "            x['rdfs:subClassOf']=truesubclass\n",
    "    return(spec_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conformsTo(spec_list,x):\n",
    "    spec_info = spec_list.loc[spec_list['name']==x['@id'].replace(\"bioschemas:\",\"\")]\n",
    "    spec_url = spec_info.iloc[0]['url']\n",
    "    conformsTodict = {\n",
    "            \"description\": \"This is used to state the Bioschemas profile that the markup relates to. The identifier can be the url for the version of this bioschemas class on github: \"+spec_url,\n",
    "            \"$ref\": \"#/definitions/conformsDefinition\"\n",
    "          }\n",
    "    conformdef={\n",
    "                \"@type\": \"CreativeWork\",\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"identifier\":{\n",
    "                    \"description\": \"The url of the version bioschemas profile that was used. For jsonschema, set @id to the identifier\",\n",
    "                    \"oneOf\": [\n",
    "                      {\n",
    "                        \"enum\": [spec_url] \n",
    "                      },\n",
    "                      {\n",
    "                        \"type\": \"string\",\n",
    "                        \"format\": \"uri\"\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                },\n",
    "                \"required\": [\n",
    "                  \"identifier\"\n",
    "                ]              \n",
    "        }\n",
    "    x['$validation']['properties']['conformsTo'] = conformsTodict\n",
    "    requirementlist = x['$validation']['required']\n",
    "    requirementlist.append('conformsTo')\n",
    "    x['$validation']['required'] = requirementlist\n",
    "    try:\n",
    "        definitiondict = x['$validation']['definitions']\n",
    "    except:\n",
    "        definitiondict = {}\n",
    "    definitiondict[\"conformsDefinition\"]=conformdef\n",
    "    x['$validation']['definitions']=definitiondict\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_schemaVersion(spec_list,x):\n",
    "    spec_info = spec_list.loc[spec_list['name']==x['@id'].replace(\"bioschemas:\",\"\")]\n",
    "    spec_url = spec_info.iloc[0]['url']\n",
    "    baseurl = \"https://bioschemas.org\"\n",
    "    versionurl = baseurl+'/'+spec_info.iloc[0]['type']+'/'+spec_info.iloc[0]['name']+'/'+spec_info.iloc[0]['version']\n",
    "    try:\n",
    "        existingversions = x[\"schema:schemaVersion\"]\n",
    "        if isinstance(schemaversions, list) == False:\n",
    "            schemaversions = existingversions.strip(\"[\").strip(\"]\").split(\",\")\n",
    "        else:\n",
    "            schemaversions = existingversions\n",
    "    except:\n",
    "        schemaversions = []\n",
    "    schemaversions.append(versionurl)\n",
    "    schemaversions.append(spec_url)\n",
    "    ## Ensure uniqueness of elements\n",
    "    x[\"schema:schemaVersion\"] = list(set(schemaversions))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_specs(spec_list):\n",
    "    bioschemas_json = {}\n",
    "    graphlist = []\n",
    "    classlist = []\n",
    "    propertylist = []\n",
    "    for eachurl in spec_list['url']:\n",
    "        rawurl = get_raw_url(eachurl)\n",
    "        r = requests.get(rawurl)\n",
    "        if r.status_code == 200:\n",
    "            cleantext = rename_namespace(spec_list,eachurl,r.text)\n",
    "            spec_json = json.loads(cleantext)\n",
    "            bioschemas_json['@context'] = check_context_url(spec_json)\n",
    "            for x in spec_json['@graph']:\n",
    "                graphlist.append(x)\n",
    "                if x[\"@type\"]==\"rdfs:Class\":\n",
    "                    classlist.append(x[\"@id\"])\n",
    "                if x[\"@type\"]==\"rdf:Property\":\n",
    "                    propertylist.append(x[\"@id\"])\n",
    "    cleanclassgraph = clean_duplicate_classes(spec_list,graphlist,classlist)\n",
    "    cleanpropsgraph = clean_duplicate_properties(graphlist, propertylist)\n",
    "    cleangraph = []\n",
    "    for z in cleanclassgraph:\n",
    "        cleangraph.append(z)\n",
    "    for a in cleanpropsgraph:\n",
    "        cleangraph.append(a)\n",
    "    conformsTo = define_conformsTo(classlist)\n",
    "    cleangraph.append(conformsTo)\n",
    "    bioschemas_json['@graph']=cleangraph\n",
    "    return(bioschemas_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duplicate_classes(spec_list,graphlist,classlist):\n",
    "    duplicates = [i for i in set(classlist) if classlist.count(i) > 1]\n",
    "    nondupes = [x for x in classlist if x not in duplicates]\n",
    "    cleanclassgraph = []\n",
    "    if len(duplicates)>0:  ## There are duplicate classes to clean up\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                y = add_conformsTo(spec_list,x)\n",
    "                z = add_schemaVersion(spec_list,y)\n",
    "                cleanclassgraph.append(z)\n",
    "            for eachclass in duplicates:\n",
    "                if x[\"@id\"]==eachclass:\n",
    "                    if \"$validation\" in x.keys():\n",
    "                        y = add_conformsTo(spec_list,x)\n",
    "                        z = add_schemaVersion(spec_list,y)\n",
    "                        cleanclassgraph.append(z)\n",
    "    else:  ## There are not duplicate classes to clean up\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                y = add_conformsTo(spec_list,x)\n",
    "                z = add_schemaVersion(spec_list,y)\n",
    "                cleanclassgraph.append(z)        \n",
    "    return(cleanclassgraph)\n",
    "\n",
    "def clean_duplicate_properties(graphlist, propertylist):            \n",
    "    duplicates = [i for i in set(propertylist) if propertylist.count(i) > 1]\n",
    "    nondupes = [x for x in propertylist if x not in duplicates]\n",
    "    if len(duplicates)>0:  ## There are duplicate properties to clean up\n",
    "        cleanpropsgraph = []\n",
    "        dupepropsgraph = []\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                cleanpropsgraph.append(x)\n",
    "            elif x[\"@id\"] in duplicates:\n",
    "                dupepropsgraph.append(x)\n",
    "        #dupepropsgraph[0][\"dummyProp\"]={\"@id\":\"dummyValue\"} #### creates dummy property for testing only\n",
    "        dupepropsdf = pd.DataFrame(dupepropsgraph)\n",
    "        for eachprop in duplicates:\n",
    "            tmpdf = dupepropsdf.loc[dupepropsdf['@id']==eachprop].copy()\n",
    "            domainlist = []\n",
    "            domainlist = [y for y in tmpdf[\"schema:domainIncludes\"] if y not in domainlist]\n",
    "            #### Get the row with the least number of NaNs (ie- the row with the most properties) to serve as the base property\n",
    "            tmpdf[\"nullcount\"]=tmpdf.isnull().sum(axis=1)\n",
    "            tmpdf.sort_values(\"nullcount\",ascending=True,inplace=True)\n",
    "            tmpdict = tmpdf.iloc[0].to_dict()\n",
    "            del tmpdict[\"nullcount\"]\n",
    "            tmpdict[\"schema:domainIncludes\"]=domainlist #### Set the domainIncludes list\n",
    "            cleanpropsgraph.append(tmpdict)       \n",
    "    else:\n",
    "        for x in graphlist:\n",
    "            if x[\"@id\"] in nondupes:\n",
    "                cleanpropsgraph.append(x)\n",
    "    return(cleanpropsgraph)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_conformsTo(classlist):\n",
    "    uniqueclasses =  list(set(classlist))\n",
    "    classidlist = [{\"@id\":x} for x in classlist]\n",
    "    conformsTo = {\n",
    "      \"@id\": \"dct:conformsTo\",\n",
    "      \"@type\": \"rdf:Property\",\n",
    "      \"rdfs:comment\": \"Used to state the Bioschemas profile that the markup relates to. The versioned URL of the profile must be used. Note that we use a CURIE in the table here but the full URL for Dublin Core terms must be used in the markup (http://purl.org/dc/terms/conformsTo), see example.\",\n",
    "      \"rdfs:label\": \"conformsTo\",\n",
    "      \"schema:domainIncludes\": classidlist,\n",
    "      \"schema:rangeIncludes\": [\n",
    "        {\"@id\": \"schema:CreativeWork\"},{\"@id\": \"schema:Text\"},{\"@id\": \"schema:Thing\"}\n",
    "      ]\n",
    "    }\n",
    "    return(conformsTo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_specs(script_path):\n",
    "    spec_list = read_csv('specifications_list.txt',delimiter='\\t',header=0)\n",
    "    bioschemas_json = merge_specs(spec_list)\n",
    "    bioschemasfile = os.path.join(script_path,'bioschemas.json')\n",
    "    with open(bioschemasfile,'w') as outfile:\n",
    "        outfile.write(json.dumps(bioschemas_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main\n",
    "script_path = \"\"\n",
    "#script_path = pathlib.Path(__file__).parent.absolute()\n",
    "update_specs(script_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "spec_list = read_csv('specifications_list.txt',delimiter='\\t',header=0)\n",
    "bioschemas_json = {}\n",
    "graphlist = []\n",
    "classlist = []\n",
    "propertylist = []\n",
    "for eachurl in spec_list['url']:\n",
    "    rawurl = get_raw_url(eachurl)\n",
    "    r = requests.get(rawurl)\n",
    "    if r.status_code == 200:\n",
    "        cleantext = rename_namespace(spec_list,eachurl,r.text)\n",
    "        spec_json = update_subclass(spec_list,eachurl,cleantext)\n",
    "        bioschemas_json['@context'] = check_context_url(spec_json)\n",
    "        for x in spec_json['@graph']:\n",
    "            graphlist.append(x)\n",
    "            if x[\"@type\"]==\"rdfs:Class\":\n",
    "                classlist.append(x[\"@id\"])\n",
    "            if x[\"@type\"]==\"rdf:Property\":\n",
    "                propertylist.append(x[\"@id\"])\n",
    "\n",
    "cleanclassgraph = clean_duplicate_classes(graphlist,classlist)\n",
    "cleanpropsgraph = clean_duplicate_properties(graphlist, propertylist)\n",
    "cleangraph = []\n",
    "for z in cleanclassgraph:\n",
    "    cleangraph.append(z)\n",
    "for a in cleanpropsgraph:\n",
    "    cleangraph.append(a)\n",
    "conformsTo = define_conformsTo(classlist)\n",
    "cleangraph.append(conformsTo)\n",
    "print(len(cleangraph))\n",
    "print(len(cleanclassgraph)+len(cleanpropsgraph))\n",
    "print(len(cleanclassgraph),len(cleanpropsgraph))\n",
    "print(cleangraph[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classidlist = [{\"@id\":x} for x in classlist]\n",
    "print(classidlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_list = read_csv('specifications_list.txt',delimiter='\\t',header=0)\n",
    "spec_info = spec_list.loc[spec_list['name']==\"Gene\"]\n",
    "print(spec_info.iloc[0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
