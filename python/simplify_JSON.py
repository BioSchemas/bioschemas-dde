import datetime
import json
import logging
import os
import pandas
import pathlib
import re # regex library
import requests
import yaml

## Logging configuration
logging.basicConfig(
    filename='simplifyJSON.log',
    filemode='w',
    encoding='utf-8',
    format='%(asctime)s %(levelname)s: %(message)s',
    level=logging.INFO)

### GLOBAL CONSTANTS
# Define location to read DDE generated JSON files
SCHEMA_SOURCE = "https://raw.githubusercontent.com/BioSchemas/specifications/master/"
# Define location to write simplified JSON Schema files
SCHEMA_TARGET = "schemas/"

def rename_file(profile, release):
    """
    Generate the filename to be used on the Bioschemas website in the form
    {ProfileName}/{version}-{status}.html
    """
    logging.debug('Entering rename_file() with profile %s, release %s' % (profile, release))
    str = profile + '/' + release + '.html'
    logging.debug('Exiting rename_file() with %s' % str)
    return str

def read_JSON_file(url):
    """
    Read in the contents of the JSON file located at the supplied URL.    
    """
    logging.debug('Entering read_JSON_file from %s' % url)
    try:
        r = requests.get(url)
        if r.status_code == 200:
            data = json.loads(r.text)
            logging.debug('Exiting read_JSON_file â€“ dictionary size %d' % len(data))
            return data
        else:
            logging.error('Got a %d error code from %s' % (r.status_code, url))
            raise Exception('Got a %d error code from %s' % (r.status_code, url))
    except requests.exceptions.RequestException as e:
        logging.error('Bad request: ' + e)
        raise SystemExit(e)

def write_YAML_file(data, filename):
    logging.debug('Entering write_YAML_file() with dictionary size %d and filename %s' % (len(data), filename))
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with open(filename, 'w') as f:
        f.write('---\n')
        f.write('# DO NOT EDIT THIS FILE\n')
        f.write('# This file was generated by bioschemas-dde code on ' +
            datetime.datetime.utcnow().strftime('%Y-%m-%d@%H:%M:%S') + ' UTC\n\n')
        yaml.dump(data, f, default_flow_style=False)
        f.write('---')
    f.close()
    logging.debug('Exiting write_YAML_file()')

def generate_metadata(data, group, previous_version, previous_release):
    logging.debug('Entering generate_metadata() with %s, group %s, previous_version %s, previous_release %s' % (str(data), group, previous_version, previous_release))
    # Set initial parameters
    metadata = {'layout': 'profile', 
                'previous_version': previous_version, 
                'previous_release': previous_release,
                'group': group,
                'changes': ''}
    data_values = data.get('@graph')[0]
    # Set name
    metadata.update({'name': data_values.get('rdfs:label')})
    # Set version
    metadata.update({'version': data_values.get('schema:schemaVersion')})
    # Set status
    status = data_values.get('schema:additionalType')
    if status.endswith('-release'):
        metadata.update({'status': 'RELEASE'})
    elif status.endswith('-draft'):
        metadata.update({'status': 'DRAFT'})
    elif status.endswith('-deprecated'):
        metadata.update({'status': 'DEPRECATED'})
    else:
        raise Exception('Unknown release status')
    # Set description
    metadata.update({'description': data_values.get('rdfs:comment')})
    # Set schema_type
    metadata.update({'schema_type': data_values.get('rdfs:subClassOf').get('@id')})
    logging.debug('Exiting generate_metadata() with ' + str(metadata))
    return metadata

def add_profile_status(version):
    """
    Add whether the profile is draft, release, or deprecated 
    """
    logging.debug('Entering add_profile_status() with ' + version)
    base_url = 'https://bioschemas.org/profiles#nav-'
    if 'deprecated' in version.lower():
        status = base_url + 'deprecated'
    elif 'release' in version.lower():
        status = base_url + 'release'
    elif 'draft' in version.lower():
        status = base_url + 'draft'
    logging.debug('Exiting add_profile_status() with ' + status)
    return status

def add_schemaVersion(profile, version):
    """
    Add the corresponding schema:schemaVersion property
    """
    logging.debug('Entering add_schemaVersion() with profile name %s and version number %s' % (profile, version))
    version = "https://bioschemas.org/profiles/" + profile + '/' + version
    logging.debug('Exiting add_schemaVersion() with ' + version)
    return version

def add_missing_properties(data, profile, version):
    """
    Add properties that are missing when JSON-Schema is written out by DDE
    """
    logging.debug('Entering add_missing_properies() with ' + str(data))
    graph_data = data["@graph"][0]
    # print(graph_data.keys())
    graph_data.update({'schema:schemaVersion': add_schemaVersion(profile, version)})
    graph_data.update({'schema:additionalType': add_profile_status(version)})
    data["@graph"][0] = graph_data
    logging.debug('Exiting add_missing_properties() with ' + str(data))
    return data

def process_profiles(script_path):
    """
    Read the specifications_list file stored on GitHub. Iterate through each
    profile in the file and generate a new schema file that Jekyll's JSON
    processor can handle.
    """
    logging.debug('Entering process_profiles() with %s' % script_path)
    # Read profile details in from file
    profiles = pandas.read_csv('../specifications_list.txt',
                delimiter='\t',
                header=0,
                usecols=["name","group","type","version","previous_version","previous_release"])
    # Replace NaNs with ''
    profiles.fillna('', inplace=True)
    # Process each profile in turn
    for index, row in profiles.iterrows():
        # Only process profile definitions
        if row['type'].lower() == 'profile':
            profile = row['name']
            release = row['version']
            group = row['group']
            previous_version = row['previous_version']
            previous_release = row['previous_release']
            logging.info('Processing %s release %s from group %s, previous_version %s, previous_release %s' % (profile, release, group, previous_version, previous_release))
            schema_file = profile + '_v' + release + '.json'
            url = SCHEMA_SOURCE + profile + "/jsonld/" + schema_file
            logging.info('Retrieving file from %s' % url)
            json_data = read_JSON_file(url)
            logging.info('Adding missing properties')
            json_data = add_missing_properties(json_data, profile, release)
            logging.info('Generating YAML properties')
            profile_data = generate_metadata(json_data, group, previous_version, previous_release)
            new_filename = SCHEMA_TARGET + rename_file(profile, release)
            logging.info('Writing data to %s' % new_filename)
            write_YAML_file(profile_data, new_filename)
        else:
            logging.info('Ignoring non-profile specification: ' + row['name'])
    logging.debug('Exiting process_profiles()')

#### Main
if __name__ == "__main__":
    script_path = pathlib.Path(__file__).parent.absolute()
    process_profiles(script_path)
    print('SUCCESS! All profiles have been processed.\nCheck %s for the generated files.'
        % SCHEMA_TARGET)
